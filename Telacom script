import paramiko
import os
import re
import pandas as pd
from datetime import datetime
import glob

# Define the expected extension for the Excel file
EXCEL_EXTENSION = '.xlsx' 

def get_sftp_connection(host, port, username, password):
    """Establishes an SFTP connection and returns the transport and SFTP client."""
    transport = None
    sftp = None
    try:
        transport = paramiko.Transport((host, port))
        transport.connect(username=username, password=password)
        sftp = paramiko.SFTPClient.from_transport(transport)
        return transport, sftp
    except Exception as e:
        print(f"Error connecting to SFTP at {host}:{port}: {e}")
        if transport:
            transport.close()
        return None, None

def close_sftp_connection(sftp, transport):
    """Closes the SFTP client and transport connection."""
    if sftp:
        sftp.close()
    if transport:
        transport.close()
    
def get_latest_remote_file(sftp, remote_file_path, file_prefix):
    """
    Lists files, finds the one matching the prefix/extension, 
    and returns the name of the latest file based on the timestamp.
    """
    
    # Dynamic Date Pattern Selection
    if 'Telamon_report_' in file_prefix:
        # Format: Telamon_report_YYYYMMDDHHMM_xxxx.xlsx
        DATE_PATTERN = r'(\d{12})'
    elif '44020 Daily OV Update-' in file_prefix:
        # Format: 44020_Daily_OV_Update-YYYY-MM-DD-HH-MM-SS.xlsx
        DATE_PATTERN = r'(\d{4}-\d{2}-\d{2}-\d{2}-\d{2}-\d{2})'
    else:
        print(f"Error: Unknown file prefix '{file_prefix}'. Cannot determine date pattern.")
        return None
        
    try:
        files = sftp.listdir(remote_file_path)
        target_files = []
        for file in files:
            # Filter by prefix AND ensure it's an XLSX file
            if file.startswith(file_prefix) and file.lower().endswith(EXCEL_EXTENSION):
                match = re.search(DATE_PATTERN, file)
                if match:
                    # Use the full timestamp (dashed or undashed) as the sort key
                    date_key = match.group(1) 
                    target_files.append((file, date_key))
        
        if not target_files:
            print(f"No Excel files found matching prefix '{file_prefix}' and extension '{EXCEL_EXTENSION}' in '{remote_file_path}'.")
            return None

        # Sort by the timestamp key (latest first)
        target_files.sort(key=lambda x: x[1], reverse=True)
        return target_files[0][0]
        
    except Exception as e:
        print(f"Error listing files in '{remote_file_path}': {e}")
        return None

def download_file_from_sftp_to_network(network_path, host, port, username, password, remote_file_path, file_prefix):
    """Connects, finds the latest file, downloads it, and closes the connection."""
    print(f"Attempting to connect to {host}:{port} for files starting with '{file_prefix}'...")
    
    transport, sftp = get_sftp_connection(host, port, username, password)
    
    if not sftp:
        return None

    try:
        latest_file_remote_name = get_latest_remote_file(sftp, remote_file_path, file_prefix)
        
        if not latest_file_remote_name:
            return None
        
        remote_full_path = os.path.join(remote_file_path, latest_file_remote_name)
        local_file_path = os.path.join(network_path, latest_file_remote_name)
        
        print(f"Latest remote file: {latest_file_remote_name}. Downloading to: {local_file_path}")
        
        # Perform the download
        sftp.get(remote_full_path, local_file_path)
        
        print(f"Download successful. File size on disk (bytes): {os.path.getsize(local_file_path)}")
        return local_file_path
        
    except Exception as e:
        print(f"An error occurred during file download for prefix '{file_prefix}': {e}")
        return None
    finally:
        close_sftp_connection(sftp, transport)

def upload_file_to_sftp(file_path, host, port, username, password, remote_path):
    """Uploads a local file to the remote SFTP path."""
    transport, sftp = None, None
    try:
        transport, sftp = get_sftp_connection(host, port, username, password)
        if sftp:
            file_name = os.path.basename(file_path)
            sftp.put(file_path, os.path.join(remote_path, file_name))
            print(f"Upload successful: {file_name} to {remote_path}")
    except Exception as e:
        print(f"An error occurred during file upload: {e}")
    finally:
        close_sftp_connection(sftp, transport)

def read_excel_file(path):
    """
    Reads the '44020 Daily OV Update' file using fixed parameters 
    to handle the header starting at Row 12 (index 11) and Column B.
    """
    file_pattern = '44020 Daily OV Update*.xlsx'
    files = glob.glob(os.path.join(path, file_pattern))

    if not files:
        # NOTE: This should technically not happen if download_file_from_sftp_to_network 
        # returned a path, but good practice to keep the check.
        print(f"No files found matching pattern '{file_pattern}' in directory '{path}'")
        return pd.DataFrame()

    most_recent_file = max(files, key=os.path.getmtime)
    print(f"Processing local file: {os.path.basename(most_recent_file)}")
    
    # --- THE FIX ---
    try:
        df = pd.read_excel(
            most_recent_file, 
            skiprows=11,  # Skips rows 1-11, starting read at Excel Row 12
            header=0,     # Treats Row 12 (the first row read) as the header
            usecols="B:"  # Starts reading from Column B, ignoring the empty Column A
        )
    except Exception as e:
        # ... (error handling)
        return pd.DataFrame()
    # ---------------

    # Standard clean-up (removed the manual header finding/slicing)
    
    # Drop any columns that are entirely empty
    df = df.loc[:, df.notnull().any(axis=0)]

    # Also drop columns that have empty strings or whitespace strings
    # Ensure all columns are strings for .applymap and .eq
    df = df.astype(str).loc[:, ~(df.applymap(lambda x: x.strip()).eq('')).all()]

    # Reset the index
    df = df.reset_index(drop=True)

    # Sanity check for the merge key
    if 'Other 1 - Site Number' not in df.columns:
        print("WARNING: 'Other 1 - Site Number' column not found in the processed 44020 file. Merge will likely fail.")
        
    return df

def process_files(quotes_file_path, tracker_file_path, network_path):
    # Read the files
    print(f"Reading tracker file: {os.path.basename(tracker_file_path)}")
    telamon_df = pd.read_excel(tracker_file_path) 
    
    # Use the robust reader for the daily update file
    daily_update_df = read_excel_file(os.path.dirname(quotes_file_path))

    if daily_update_df.empty:
        print(" ABORT: The '44020 Daily OV Update' file is empty or failed to load correctly. Aborting comparison.")
        return 

    # Merge the DataFrames
    print("Merging dataframes...")
    merged_df = pd.merge(telamon_df, daily_update_df, 
                         left_on='P:Viaero Root ID', 
                         right_on='Other 1 - Site Number', 
                         suffixes=('_telamon', '_daily_update'), 
                         how='outer')

    # Identify differences
    diff_df = pd.DataFrame()
    
    # Identify common columns to check for differences
    columns_to_check = set(telamon_df.columns) & set(daily_update_df.columns)
    
    for column in columns_to_check:
        if column not in ['P:Viaero Root ID', 'Other 1 - Site Number']: # Skip the merge keys
            telamon_col = f'{column}_telamon'
            daily_col = f'{column}_daily_update'
            
            if telamon_col in merged_df.columns and daily_col in merged_df.columns:
                temp_df = merged_df[
                    # Compare strings, strip whitespace, and handle NaNs/empty strings
                    merged_df[telamon_col].astype(str).fillna('').str.strip() != 
                    merged_df[daily_col].astype(str).fillna('').str.strip()
                ]
                diff_df = pd.concat([diff_df, temp_df])
                
    # Remove duplicates from the differences found
    diff_df = diff_df.drop_duplicates(subset=['P:Viaero Root ID', 'Other 1 - Site Number']).copy() 

    # Create output DataFrame
    output_df = pd.DataFrame()
    
    # Safely get the 'Project ID' (prefer the Telamon version as it's the source)
    output_df['Project ID'] = diff_df.get('Project ID_telamon', diff_df.get('Project ID', ''))
    
    output_df['Workplan Name'] = 'Viaero_Workplan'

    # Map Project ID
    output_df['Mapped Project ID'] = output_df['Project ID'].astype(str).apply(lambda x: x.replace('V:(F', 'PF').replace('V:(A', 'AF'))

    # Add other columns from Telamon_report_ file (left side of outer merge)
    for column in telamon_df.columns:
        # Use the suffixed column name for the merged difference file
        telamon_col = column if column in ['Project ID'] else f'{column}_telamon'
        
        if telamon_col in diff_df.columns:
            output_df[column] = diff_df[telamon_col]
        
    # Final cleanup: drop rows where all values are NaN/empty EXCEPT 'Workplan Name'
    output_df = output_df.dropna(how='all', subset=output_df.columns.difference(['Workplan Name'])).reset_index(drop=True)

    # Save output file
    output_file_name = f'TELAMON_IMPORT_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv' 
    output_path = os.path.join(network_path, output_file_name)
    output_df.to_csv(output_path, index=False)
    print(f"Output file saved successfully: {output_path}")

    # Upload file to SFTP
    sftp_host = '54.225.75.239'
    sftp_port = 22
    sftp_username = 'sea2_es'
    sftp_password = 'M5v3WV3ThaG9'
    sftp_remote_path = '/home/samsung_sea2/es/Inbound/Rancomm/Telamon Reports/'
    print("Attempting to upload the final CSV...")
    upload_file_to_sftp(output_path, sftp_host, sftp_port, sftp_username, sftp_password, sftp_remote_path)

def download_and_process_files():
    try:
        # --- CONFIGURATION START ---
        network_path = r'C:\Users\l5.lopez\Downloads\00_to delete' # Verify this path is correct
        
        # SFTP 1: Telamon Tracker
        host1 = '54.225.75.239'
        port1 = 22
        username1 = 'sea2_es'
        password1 = 'M5v3WV3ThaG9'
        remote_file_path1 = '/home/samsung_sea2/es/Rancomm/'
        file_prefix1 = 'Telamon_report_'
        
        # SFTP 2: 44020 Daily OV Update
        host2 = '105.52.12.194'
        port2 = 1022
        username2 = 'samrftool'
        password2 = 'nyHOPokaG3SP'
        remote_file_path2 = '/var/data/Support_Data/quickbase/Telamon'
        file_prefix2 = '44020 Daily OV Update-'
        # --- CONFIGURATION END ---

        # Download files
        tracker_file_path = download_file_from_sftp_to_network(network_path, host1, port1, username1, password1, remote_file_path1, file_prefix1)
        quotes_file_path = download_file_from_sftp_to_network(network_path, host2, port2, username2, password2, remote_file_path2, file_prefix2)

        if tracker_file_path and quotes_file_path:
            process_files(quotes_file_path, tracker_file_path, network_path)
        else:
            print("One or both files failed to download. Comparison aborted.")
    except Exception as e:
        print(f"An error occurred during file processing: {e}")

# Execute the main function
download_and_process_files()
