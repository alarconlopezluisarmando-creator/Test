def download_file_from_sftp_to_network(network_path, host, port, username, password, remote_file_path, file_prefix):
    print(f"Attempting to connect to {host}:{port} for files starting with '{file_prefix}'...")
    
    # Define a regex pattern to find a timestamp (YYYYMMDD or similar) for sorting
    # This assumes the date/timestamp is the most reliable part for determining "latest".
    # Adjust this regex if your file names have a different date/time format.
    DATE_PATTERN = r'(\d{8,})' 

    transport = None
    sftp = None
    try:
        transport = paramiko.Transport((host, port))
        transport.connect(username=username, password=password)
        sftp = paramiko.SFTPClient.from_transport(transport)
        
        files = sftp.listdir(remote_file_path)
        
        # 1. Filter and Prepare files for robust sorting
        target_files = []
        for file in files:
            if file.startswith(file_prefix):
                match = re.search(DATE_PATTERN, file)
                if match:
                    # Use the extracted date string for sorting key
                    date_key = match.group(1)
                    target_files.append((file, date_key))
                else:
                    # Fallback for files without a date, use filename as key
                    target_files.append((file, file)) 
        
        if not target_files:
            print(f"No files found starting with '{file_prefix}' in '{remote_file_path}'.")
            return None

        # 2. Sort by the extracted date key (reverse=True for latest)
        target_files.sort(key=lambda x: x[1], reverse=True)
        
        latest_file = target_files[0][0]
        
        local_file_path = os.path.join(network_path, latest_file)
        remote_full_path = os.path.join(remote_file_path, latest_file)
        
        print(f"Latest file found: {latest_file}. Downloading to {local_file_path}...")
        
        sftp.get(remote_full_path, local_file_path)
        
        print("Download successful.")
        return local_file_path
        
    except Exception as e:
        print(f"An error occurred during file download for prefix '{file_prefix}': {e}")
        return None
    finally:
        if sftp:
            sftp.close()
        if transport:
            transport.close()
        
# The upload_file_to_sftp, download_and_process_files, and process_files functions remain mostly the same. 
# Only process_files is shown below for a small fix.

def upload_file_to_sftp(file_path, host, port, username, password, remote_path):
    # ... (Keep this function as is)
    pass 

def process_files(quotes_file_path, tracker_file_path, network_path):
    # Read the files
    telamon_df = pd.read_csv(tracker_file_path)
    
    # ‚ö†Ô∏è POTENTIAL FIX HERE: The file 44020_Daily_OV_Update is the Excel file.
    # Check your sheet name! If not specified, pandas defaults to the first sheet (0).
    daily_update_df = pd.read_excel(quotes_file_path, skiprows=11, usecols="B:XFD") 

    # Merge the DataFrames
    # The current merge uses the entire first column of each DataFrame.
    # Ensure the first column of each file is the 'Project ID' or common key.
    merged_df = pd.merge(telamon_df, daily_update_df, 
                         left_on=telamon_df.columns[0], 
                         right_on=daily_update_df.columns[0], 
                         suffixes=('_telamon', '_daily_update'), 
                         how='outer')

    # Identify differences
    diff_df = pd.DataFrame()
    for column in telamon_df.columns:
        if column != telamon_df.columns[0]:
            # This comparison can fail if columns contain mixed types (e.g., int and string) or NaN.
            # Using .fillna to treat NaNs as equal and .astype(str) for safer comparison is best practice.
            temp_df = merged_df[
                merged_df[f'{column}_telamon'].astype(str).fillna('') != 
                merged_df[f'{column}_daily_update'].astype(str).fillna('')
            ]
            diff_df = pd.concat([diff_df, temp_df])
    diff_df = diff_df.drop_duplicates()

    # ... rest of the function (Keep as is)
    
# ... (Keep download_and_process_files as is)

# download_and_process_files() # Don't run this here, just showing the code structure

Update download funtion. 

import paramiko
import os
import re 
from datetime import datetime

# Define the expected extension for the Excel file
EXCEL_EXTENSION = '.xlsx'

def download_file_from_sftp_to_network(network_path, host, port, username, password, remote_file_path, file_prefix):
    print(f"Attempting to connect to {host}:{port} for files starting with '{file_prefix}'...")
    
    # üéØ UPDATED PATTERN: Matches the 'YYYY-MM-DD-HH-MM-SS' format in your filename.
    # This ensures accurate sorting by the full timestamp.
    DATE_PATTERN = r'(\d{4}-\d{2}-\d{2}-\d{2}-\d{2}-\d{2})' 

    transport = None
    sftp = None
    try:
        transport = paramiko.Transport((host, port))
        transport.connect(username=username, password=password)
        sftp = paramiko.SFTPClient.from_transport(transport)
        
        files = sftp.listdir(remote_file_path)
        
        target_files = []
        for file in files:
            # Filter by prefix AND ensure it's an XLSX file
            if file.startswith(file_prefix) and file.lower().endswith(EXCEL_EXTENSION):
                match = re.search(DATE_PATTERN, file)
                if match:
                    # Use the full timestamp (e.g., '2025-10-22-07-00-03') as the sort key
                    date_key = match.group(1) 
                    target_files.append((file, date_key))
        
        if not target_files:
            print(f"No Excel files found matching prefix '{file_prefix}' and pattern in '{remote_file_path}'.")
            return None

        # Sort by the timestamp key (latest first)
        target_files.sort(key=lambda x: x[1], reverse=True)
        
        latest_file_remote_name = target_files[0][0]
        remote_full_path = os.path.join(remote_file_path, latest_file_remote_name)
        
        # The remote name already contains the correct .xlsx extension
        local_file_path = os.path.join(network_path, latest_file_remote_name)
        
        print(f"Latest remote file: {latest_file_remote_name}. Downloading to: {local_file_path}")
        
        # Perform the download
        sftp.get(remote_full_path, local_file_path)
        
        print(f"Download successful. File size on disk (bytes): {os.path.getsize(local_file_path)}")
        return local_file_path
        
    except Exception as e:
        print(f"An error occurred during file download for prefix '{file_prefix}': {e}")
        return None
    finally:
        if sftp:
            sftp.close()
        if transport:
            transport.close()

# Note: The 're' import error will only stop if you haven't added 'import re' 
# to the top of your script alongside 'import paramiko', 'import os', etc.


