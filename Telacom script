import paramiko
import os
import re
import pandas as pd
from datetime import datetime
import glob

# Define the expected extension for the Excel file
EXCEL_EXTENSION = '.xlsx' 

# (get_sftp_connection and close_sftp_connection remain the same)
def get_sftp_connection(host, port, username, password):
    """Establishes an SFTP connection and returns the transport and SFTP client."""
    transport = None
    sftp = None
    try:
        transport = paramiko.Transport((host, port))
        transport.connect(username=username, password=password)
        sftp = paramiko.SFTPClient.from_transport(transport)
        return transport, sftp
    except Exception as e:
        print(f"Error connecting to SFTP at {host}:{port}: {e}")
        if transport:
            transport.close()
        return None, None

def close_sftp_connection(sftp, transport):
    """Closes the SFTP client and transport connection."""
    if sftp:
        sftp.close()
    if transport:
        transport.close()
    
def get_latest_remote_file(sftp, remote_file_path, file_prefix):
    """
    Lists files, finds the one matching the prefix/extension, 
    and returns the name of the latest file based on the timestamp.
    
    The date pattern is now dynamically selected based on the file prefix.
    """
    
    # FIX 1: Dynamic Date Pattern Selection
    if 'Telamon_report_' in file_prefix:
        # Format: Telamon_report_YYYYMMDDHHMM_xxxx.xlsx
        DATE_PATTERN = r'(\d{12})'
    elif '44020 Daily OV Update-' in file_prefix:
        # Format: 44020_Daily_OV_Update-YYYY-MM-DD-HH-MM-SS.xlsx
        DATE_PATTERN = r'(\d{4}-\d{2}-\d{2}-\d{2}-\d{2}-\d{2})'
    else:
        # Default pattern if needed, but safer to raise an error or use one of the above
        print(f"Error: Unknown file prefix '{file_prefix}'. Cannot determine date pattern.")
        return None
        
    try:
        files = sftp.listdir(remote_file_path)
        target_files = []
        for file in files:
            # Filter by prefix AND ensure it's an XLSX file
            if file.startswith(file_prefix) and file.lower().endswith(EXCEL_EXTENSION):
                match = re.search(DATE_PATTERN, file)
                if match:
                    # Use the full timestamp (dashed or undashed) as the sort key
                    date_key = match.group(1) 
                    target_files.append((file, date_key))
        
        if not target_files:
            print(f"No Excel files found matching prefix '{file_prefix}' and extension '{EXCEL_EXTENSION}' in '{remote_file_path}'.")
            return None

        # Sort by the timestamp key (latest first)
        target_files.sort(key=lambda x: x[1], reverse=True)
        return target_files[0][0]
        
    except Exception as e:
        print(f"Error listing files in '{remote_file_path}': {e}")
        return None

def download_file_from_sftp_to_network(network_path, host, port, username, password, remote_file_path, file_prefix):
    """Connects, finds the latest file, downloads it, and closes the connection."""
    print(f"Attempting to connect to {host}:{port} for files starting with '{file_prefix}'...")
    
    transport, sftp = get_sftp_connection(host, port, username, password)
    
    if not sftp:
        return None

    try:
        latest_file_remote_name = get_latest_remote_file(sftp, remote_file_path, file_prefix)
        
        if not latest_file_remote_name:
            return None
        
        remote_full_path = os.path.join(remote_file_path, latest_file_remote_name)
        local_file_path = os.path.join(network_path, latest_file_remote_name)
        
        print(f"Latest remote file: {latest_file_remote_name}. Downloading to: {local_file_path}")
        
        # Perform the download
        sftp.get(remote_full_path, local_file_path)
        
        print(f"Download successful. File size on disk (bytes): {os.path.getsize(local_file_path)}")
        return local_file_path
        
    except Exception as e:
        print(f"An error occurred during file download for prefix '{file_prefix}': {e}")
        return None
    finally:
        close_sftp_connection(sftp, transport)

def upload_file_to_sftp(file_path, host, port, username, password, remote_path):
    # (upload_file_to_sftp remains the same)
    transport, sftp = None, None
    try:
        transport, sftp = get_sftp_connection(host, port, username, password)
        if sftp:
            file_name = os.path.basename(file_path)
            sftp.put(file_path, os.path.join(remote_path, file_name))
            print(f"Upload successful: {file_name} to {remote_path}")
    except Exception as e:
        print(f"An error occurred during file upload: {e}")
    finally:
        close_sftp_connection(sftp, transport)

# --- (The rest of your processing code uses the previous fix for the empty DataFrame) ---

def download_and_process_files():
    try:
        network_path = r'C:\Users\l5.lopez\Downloads\00_to delete'
        
        # SFTP credentials
        host1 = '54.225.75.239'
        port1 = 22
        username1 = 'sea2_es'
        password1 = 'M5v3WV3ThaG9'
        remote_file_path1 = '/home/samsung_sea2/es/Rancomm/'
        file_prefix1 = 'Telamon_report_'
        
        host2 = '105.52.12.194'
        port2 = 1022
        username2 = 'samrftool'
        password2 = 'nyHOPokaG3SP'
        remote_file_path2 = '/var/data/Support_Data/quickbase/Telamon'
        file_prefix2 = '44020 Daily OV Update-'

        # Download files (uses the function with dynamic date pattern)
        tracker_file_path = download_file_from_sftp_to_network(network_path, host1, port1, username1, password1, remote_file_path1, file_prefix1)
        quotes_file_path = download_file_from_sftp_to_network(network_path, host2, port2, username2, password2, remote_file_path2, file_prefix2)

        if tracker_file_path and quotes_file_path:
            process_files(quotes_file_path, tracker_file_path, network_path)
        else:
            print("One or both files failed to download. Comparison aborted.")
    except Exception as e:
        print(f"An error occurred during file processing: {e}")

def read_excel_file(path):
    file_pattern = '44020 Daily OV Update*.xlsx'
    files = glob.glob(os.path.join(path, file_pattern))

    if not files:
        raise FileNotFoundError(f"No files found matching pattern '{file_pattern}' in directory '{path}'")

    most_recent_file = max(files, key=os.path.getmtime)

    excel_file = pd.read_excel(most_recent_file, header=None)

    # Find the row that starts with 'Project ID'
    header_row = excel_file[excel_file.eq('Project ID').any(axis=1)].index[0]

    # Create the DataFrame, skipping the rows before the header row
    df = excel_file.iloc[header_row:].reset_index(drop=True)

    # Set the first row as the header
    df.columns = df.iloc[0]
    df = df.iloc[1:].reset_index(drop=True)

    # Drop any columns that are entirely empty
    df = df.loc[:, df.notnull().any(axis=0)]

    # Also drop columns that have empty strings or whitespace strings
    df = df.loc[:, ~(df.applymap(lambda x: str(x).strip()).eq('')).all()]

    # Reset the index
    df = df.reset_index(drop=True)

    return df

def process_files(quotes_file_path, tracker_file_path, network_path):
    # Read the files
    telamon_df = pd.read_excel(tracker_file_path) 
    
    daily_update_df = read_excel_file(os.path.dirname(quotes_file_path))

    if daily_update_df.empty:
        print(" WARNING: The '44020_Daily_OV_Update' file is still coming empty. Please verify the actual row number of 'Project ID' in the Excel file.")

    # Merge the DataFrames
    merged_df = pd.merge(telamon_df, daily_update_df, 
                         left_on='P:Viaero Root ID', 
                         right_on='Other 1 - Site Number', 
                         suffixes=('_telamon', '_daily_update'), 
                         how='outer')

    # Identify differences
    diff_df = pd.DataFrame()
    for column in telamon_df.columns:
        if column != 'P:Viaero Root ID':
            telamon_col = f'{column}_telamon'
            daily_col = f'{column}_daily_update'
            
            if telamon_col in merged_df.columns and daily_col in merged_df.columns:
                temp_df = merged_df[
                    merged_df[telamon_col].astype(str).fillna('') != 
                    merged_df[daily_col].astype(str).fillna('')
                ]
                diff_df = pd.concat([diff_df, temp_df])
    diff_df = diff_df.drop_duplicates()

    # Create output DataFrame
    output_df = pd.DataFrame()
    output_df['Project ID'] = diff_df['Project ID']
    output_df['Workplan Name'] = 'Viaero_Workplan'

    # Map Project ID
    output_df['Mapped Project ID'] = output_df['Project ID'].apply(lambda x: str(x).replace('V:(F', 'PF').replace('V:(A', 'AF'))

    # Add other columns from Telamon_report_ file
    for column in telamon_df.columns:
        telamon_col = column if column == 'Project ID' else f'{column}_telamon'
        
        if telamon_col in diff_df.columns:
            output_df[column] = diff_df[telamon_col]
        elif column in diff_df.columns:
            output_df[column] = diff_df[column]


    # Save output file
    output_file_name = f'TELAMON_IMPORT_{datetime.now().strftime("%Y%m%d")}.csv'
    output_path = os.path.join(network_path, output_file_name)
    output_df.to_csv(output_path, index=False)

    # Upload file to SFTP
    sftp_host = '54.225.75.239'
    sftp_port = 22
    sftp_username = 'sea2_es'
    sftp_password = 'M5v3WV3ThaG9'
    sftp_remote_path = '/home/samsung_sea2/es/Inbound/Rancomm/Telamon Reports/'
    upload_file_to_sftp(output_path, sftp_host, sftp_port, sftp_username, sftp_password, sftp_remote_path)

download_and_process_files()
