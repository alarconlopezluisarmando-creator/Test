def process_and_compare_files(quote_report_path, quote_tracker_path):
    """
    Reads the two files, cleans and standardizes the data, and performs the comparison.
    """
    print(f"\n--- Starting comparison between: {os.path.basename(quote_report_path)} and {os.path.basename(quote_tracker_path)} ---")
    
    # Define a regex pattern to reliably extract the core Quote ID (e.g., 'SV0282.00')
    QUOTE_ID_PATTERN = r'([A-Z]{2}\d{4}\.\d{1,2})' 
    
    try:
        # üéØ FIX 1: Read the Quote Report file as CSV.
        # Assuming the 'Project ID' header is in the 11th row, we need to skip 10 rows.
        # We also need to specify the delimiter if it's not a comma (assuming comma for now).
        df_quotes = pd.read_csv(quote_report_path, skiprows=10) 
        
        # Read the Quote Tracker file (Telamon_report_) as Excel (assuming it's .xlsx)
        df_tracker = pd.read_excel(quote_tracker_path, engine='openpyxl')
        
    except FileNotFoundError as e:
        print(f"Error: One of the downloaded files was not found at its local path. Details: {e}")
        return
    except Exception as e:
        print(f"Error reading files: {e}")
        return

    # Clean column names
    df_quotes.columns = df_quotes.columns.str.strip()
    df_tracker.columns = df_tracker.columns.str.strip()
    
    # Check if the Quote Report file is empty due to incorrect header/column reading
    if df_quotes.empty:
        print("‚ö†Ô∏è ERROR: The Quote Report DataFrame is empty. Verify the `skiprows` parameter or delimiter in pd.read_csv().")
        return

    # --- Data Standardization for Merge ---

    # 1. Process Quotes Report (Now CSV)
    # The header is now expected to be 'Project ID', 'Other 1 - Site ID', 'Other 1 - Site Number', etc.
    if 'Other 1 - Site Number' in df_quotes.columns:
        df_quotes.rename(columns={'Other 1 - Site Number': 'Site #'}, inplace=True)
        df_quotes['Site #'] = df_quotes['Site #'].astype(str).str.strip().str.upper().str.zfill(4)
    else:
        # If 'Other 1 - Site Number' isn't found, check for the column name we've been using previously.
        print("Error: The required 'Other 1 - Site Number' column was not found in the report.")
        return
    
    if 'Document' in df_quotes.columns:
        df_quotes['QT:Quote ID'] = df_quotes['Document'].astype(str).str.extract(QUOTE_ID_PATTERN).fillna('')
        if df_quotes['QT:Quote ID'].eq('').all():
             print("Error: Failed to extract a valid Quote ID from the 'Document' column using the regex pattern.")
             return
    else:
        print("Error: The required 'Document' column was not found in the report.")
        return
    
    # Robust Review History Extraction (Fix for date/time error)
    if 'Review History' in df_quotes.columns:
        review_history_series = df_quotes['Review History'].astype(str).str.strip()
        
        # FIXED REGEX: Allows flexible spacing before the AM/PM designation
        DATE_REGEX = r'.*?\[\s*(\w{3}[-]\d{1,2}[-]\d{2}\s+\d{1,2}:\d{2}\s*[AP]M)\s*\].*'
    
        date_string_series = review_history_series.str.extract(DATE_REGEX, expand=False).str.strip()
    
        df_quotes['Review History DT'] = pd.to_datetime(
            date_string_series,
            format='%b-%d-%y %I:%M %p',
            errors='coerce' 
        )
        
        if df_quotes['Review History DT'].isna().all():
             first_failing_value = date_string_series[df_quotes['Review History DT'].isna() & date_string_series.notna()].iloc[0] if not date_string_series[df_quotes['Review History DT'].isna() & date_string_series.notna()].empty else 'None Found'
             print(f"Error: Failed to extract a valid date/time from the 'Review History' column. Check the date format or the regex pattern.")
             print(f"First non-parsed value: '{first_failing_value}'")
             return
    
        df_quotes = df_quotes.sort_values(by='Review History DT', ascending=False).drop_duplicates(
            subset='QT:Quote ID', 
            keep='first'
        )
        
        df_quotes = df_quotes.drop(columns=['Review History DT'])
    else:
        print("Error: The required 'Review History' column was not found in the report.")
        return

    # 2. Process Quote Tracker (Telamon_report) - Remains the same
    if 'QT:Root Cell ID' in df_tracker.columns:
        df_tracker.rename(columns={'QT:Root Cell ID': 'Site #'}, inplace=True)
        df_tracker['Site #'] = df_tracker['Site #'].astype(str).str.strip().str.upper().str.zfill(4)
    else:
        print("Error: The required 'QT:Root Cell ID' was not found in the Tracker file.")
        return
    
    if 'QT:Quote ID' in df_tracker.columns:
        df_tracker['QT:Quote ID'] = df_tracker['QT:Quote ID'].astype(str).str.extract(QUOTE_ID_PATTERN).fillna('')
    else:
        print("Error: The required 'QT:Quote ID' column was not found in the Tracker file.")
        return

    # --- Merge and Comparison Logic ---
    
    # Create Composite Merge Key
    df_quotes['MERGE_KEY'] = df_quotes['Site #'] + '_' + df_quotes['QT:Quote ID']
    df_tracker['MERGE_KEY'] = df_tracker['Site #'] + '_' + df_tracker['QT:Quote ID']

    merged_df = pd.merge(
        df_quotes,
        df_tracker,
        on='MERGE_KEY', 
        how='left',
        suffixes=('_quotes', '_tracker')
    )
    
    # ... (Rest of the comparison and output logic remains the same) ...

    # Diagnostic Check
    if merged_df['Site #_tracker'].isnull().all() and not df_quotes.empty:
        print("\n*** WARNING: ALL TRACKER COLUMNS ARE LIKELY BLANK (MERGE FAILURE) ***")
        
    # Requirement 3 & 4: Concatenate key columns
    merged_df['Conca_quotes'] = merged_df[[
        'Site #_quotes', 'Document Type - RAN', 'Review History',
        'Doc Review Status Text', 'Rejection Notes', 'Date Approved'
    ]].astype(str).agg('|'.join, axis=1)

    merged_df['Conca_tracker'] = merged_df[[
        'Site #_tracker', 'QT:QB - Document Type', 'QT:QB - Review History',
        'QT:QB - Doc Review Status Text', 'QT:QB - Rejection Notes', 'QT:QB - Date Approved'
    ]].astype(str).agg('|'.join, axis=1)

    # Requirement 5: Compare and find differences
    df_diff = merged_df[(merged_df['Conca_quotes'] != merged_df['Conca_tracker']) | merged_df['Site #_tracker'].isnull()]
    
    df_diff = df_diff[df_diff['QT:Quote ID_quotes'].notna() & (df_diff['QT:Quote ID_quotes'] != '')]

    # Remove duplicates and keep the latest
    df_diff = df_diff.sort_values(by=['QT:Quote ID_quotes', 'QT:QB - Review History'], ascending=[True, False])
    df_diff = df_diff.drop_duplicates(subset='QT:Quote ID_quotes', keep='first')
    
    # --- Output Files ---
    
    if not df_diff.empty:
        # DEBUG/COMPARISON FILE
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        debug_file_name = f"DEBUG_Comparison_Differences_Raw_{timestamp}.xlsx"
        debug_output_path = os.path.join(os.path.dirname(quote_report_path), debug_file_name) 
        df_diff.to_excel(debug_output_path, index=False)
        print(f"\n*** COMPARISON DEBUG FILE CREATED ***: Differences saved to: {debug_output_path}")

        # FINAL PROCESSED REPORT
        df_output = df_diff[[
            'QT:Quote ID_quotes', 
            'Submittal Date',
            'Document Type - RAN',
            'Review History',
            'Doc Review Status Text',
            'Date Approved',
            'Rejection Notes',
            'Redline Notes'
        ]].rename(columns={
            'QT:Quote ID_quotes': 'QUOTE_TRACKER_XITOR_KEY',
            'Submittal Date': 'QT_SUBMITTAL_DATE',
            'Document Type - RAN': 'QT_QB__DOCUMENT_TYPE',
            'Review History': 'QT_QB__REVIEW_HISTORY',
            'Doc Review Status Text': 'QT_QB__DOC_REVIEW_STATUS_TEXT',
            'Date Approved': 'QT_QB__DATE_APPROVED',
            'Rejection Notes': 'QT_QB__REJECTION_NOTES',
            'Redline Notes': 'QT_QB_RED_LINE_NOTES'
        })
        
        timestamp = datetime.now().strftime('%m%d%Y_%H%M%S')
        output_file_name = f"QB_QUOTE_{timestamp}.xlsx"
        output_path = os.path.join(os.path.dirname(quote_report_path), output_file_name)
        df_output.to_excel(output_path, index=False)
        print(f"Final Discrepancy Report saved to: {output_path}")
