import pandas as pd
import pyodbc
from sqlalchemy import create_engine

server = '105.52.12.164,1433'
server_tcp = 'tcp:' + server
USERNAME = 'rfuseradmin'
PSSWD = 'Newtisgreat!'
DB = 'RANCOMM'

import pandas as pd
import pyodbc
from sqlalchemy import create_engine
import numpy as np

# --- 1. Database Configuration ---
server = '105.52.12.164,1433'
server_tcp = 'tcp:' + server
USERNAME = 'rfuseradmin'
PSSWD = 'Newtisgreat!'
DB = 'RANCOMM'

# Configure the connection string and engine
connection_string = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server_tcp};DATABASE={DB};Encrypt=yes;TrustServerCertificate=yes;UID={USERNAME};PWD={PSSWD}'
engine = create_engine(f'mssql+pyodbc:///?odbc_connect={connection_string}', fast_executemany=True)

# --- 2. Data Fetch ---
query = """SELECT 
       [market_id]
      ,[NE_ID]
      ,[NE_PREFIX]
      ,[ne_type]
      ,[EMS NAME]
      ,[NE NAME]
      ,[NE SOFTWARE]
      ,[region]
      ,[eNB_ID]
  FROM [RANCOMM].[dbo].[daily_sites_mapping]"""

try:
    df = pd.read_sql(query, engine)
    print(f"Successfully fetched {len(df)} records. üíæ")
except Exception as e:
    print(f"‚ùå Error connecting to database or fetching data: {e}")
    exit()

# --- 3. Filtering and Categorization ---

# Define the ne_type values corresponding to your three count groups
CDU30_TYPE = 'udu_cnf'
UADPF_TYPE = 'macro_indoor_dist'
# üö® ACTION REQUIRED: Replace 'nsb_type' with the actual ne_type for NSB sites
NSB_TYPE = 'nsb_type' 

# Filter for the relevant ne_types
df = df[(df['ne_type'] == CDU30_TYPE) | (df['ne_type'] == UADPF_TYPE) | (df['ne_type'] == NSB_TYPE)]

# Define the conditions for SC. (Using your last provided list)
sc_conditions = ['sc_od', 'sc_ib', 'das_od', 'das_ib', 'cran_das', '_ib']

# Create a new column to categorize NE NAME
df['NE NAME'] = df['NE NAME'].str.strip().str.lower()
df['category'] = df['NE NAME'].apply(lambda x: 'SC' if any(cond in x for cond in sc_conditions) else 'Macro')

# --- 4. Final Report Aggregation and Formatting ---

# Map the raw ne_type values to the desired base column names
ne_type_map = {
    CDU30_TYPE: 'CDU30',
    UADPF_TYPE: 'uADPF',
    NSB_TYPE: 'NSB'
}

# Create a temporary column with the desired header name
df['technology'] = df['ne_type'].map(ne_type_map)

# Group by region, the 'technology', and the 'category' (Macro/SC)
report_series = df.groupby(['region', 'technology', 'category'])['NE_ID'].count()

# Unstack all levels except 'region' to get a MultiIndex column structure
report = report_series.unstack(level=['technology', 'category']).fillna(0).astype(int)

# --- 5. Flatten the Column Headers (The Key Change) ---

# Flatten the MultiIndex columns using a list comprehension
# This converts ('CDU30', 'Macro') into 'CDU30_Macro'
report.columns = [f'{tech}_{cat}' for tech, cat in report.columns]

# Define the explicit order for the flat columns
ordered_cols_flat = [
    'CDU30_Macro', 'CDU30_SC', 
    'uADPF_Macro', 'uADPF_SC', 
    'NSB_Macro', 'NSB_SC'
]

# Reorder the final report columns, filtering for existing ones
final_cols = [col for col in ordered_cols_flat if col in report.columns]
report = report[final_cols]

# Clean up index name
report.index.name = 'Region / Site Count'

print("\n" + "="*80)
print("     Samsung Site Count Report with FLAT Column Headers")
print("="*80)
print(report)
