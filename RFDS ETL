import pandas as pd
import numpy as np
from datetime import datetime
import os
# Assuming the necessary SFTP functions (download, upload) and Alteryx.write are defined elsewhere.
# For simplicity, this function focuses on the data transformation and local saving.

def RFDS_Update(df_quickbase, df_rfds_status, df_rfds_report, output_path, sftp_upload_function=None):
    """
    Performs data manipulation, lookups, and conditional logic 
    on the QuickBase and RFDS status/report files, and saves the final output.

    Args:
        df_quickbase (pd.DataFrame): Data from QuickBase_RFDS_CD_TED.xlsx.
        df_rfds_status (pd.DataFrame): Data from the latest RFDS_status_report_*.csv.
        df_rfds_report (pd.DataFrame): Data from the latest RFDS_report_*.csv (for step 6).
        output_path (str): Local directory path to save the output file.
        sftp_upload_function (function, optional): A function to handle the SFTP upload. 
                                                  Defaults to None (only local save).
    Returns:
        pd.DataFrame: The final processed DataFrame.
    """
    
    print("Starting RFDS Update process...")

    # --- 1. Filter df_quickbase ---
    # Filter the column 'WPK:OV Work Package ID' does not contain 'Viaero Trial'
    column_to_filter = 'WPK:OV Work Package ID'
    if column_to_filter in df_quickbase.columns:
        # Using .str.contains with 'case=False' for case-insensitive matching 
        # and '~' for negation (does NOT contain)
        initial_rows = len(df_quickbase)
        df_quickbase = df_quickbase[~df_quickbase[column_to_filter].astype(str).str.contains('Viaero Trial', na=False, case=False)]
        print(f"1. Filtered '{column_to_filter}'. Removed {initial_rows - len(df_quickbase)} rows containing 'Viaero Trial'.")
    else:
        print(f"Warning: Column '{column_to_filter}' not found in QuickBase file.")


    # --- 2. Complete "site #" in df_rfds_status with "0" until 4 digits ---
    site_col = 'site #'
    if site_col in df_rfds_status.columns:
        # Convert to string, then use .str.zfill(4) to pad with zeros
        df_rfds_status[site_col] = df_rfds_status[site_col].astype(str).str.strip().str.zfill(4)
        print("2. Padded 'site #' in RFDS status file to 4 digits with leading zeros.")
    else:
        print(f"Warning: Column '{site_col}' not found in RFDS status file.")


    # --- Prepare for Merges ---
    # Create the composite key 'P:Viaero Root ID + site #' for VLOOKUPs
    df_quickbase['Join_Key'] = df_quickbase['P:Viaero Root ID'].astype(str) + df_quickbase['site #'].astype(str)
    
    # Check if necessary columns exist in df_rfds_status
    required_cols_status = ['P:Viaero Root ID', site_col, 'RFDS Review Status Text', 'RFDS']
    if all(col in df_rfds_status.columns for col in required_cols_status):
        df_rfds_status['Join_Key'] = df_rfds_status['P:Viaero Root ID'].astype(str) + df_rfds_status[site_col].astype(str)
        # --- 4. Handle Duplicates in df_rfds_status (Use 'RFDS' to bring the latest data) ---
        # Assuming 'RFDS' is a date/time or unique identifier where a higher value means 'latest'
        # Sort by 'Join_Key' and 'RFDS', then keep the LAST (latest) occurrence
        df_rfds_status = df_rfds_status.sort_values(by=['Join_Key', 'RFDS'], ascending=[True, True]).drop_duplicates(subset=['Join_Key'], keep='last')
        print("4. Handled duplicates in RFDS status file by keeping the latest based on 'RFDS' column.")
    else:
        print("Error: Missing required columns in RFDS status file for joining/deduplication.")
        # Proceed with empty join key for partial steps
        df_rfds_status['Join_Key'] = ''


    # --- 3. VLOOKUP using P:Viaero Root ID and site # (Merge df_quickbase with df_rfds_status) ---
    # Merge using the composite key. We only need a few columns from status file for now.
    cols_to_bring_status = ['Join_Key', 'RFDS Review Status Text']
    df_quickbase = pd.merge(
        df_quickbase,
        df_rfds_status[cols_to_bring_status],
        on='Join_Key',
        how='left',
        suffixes=('_QB', '_RFDS_STATUS') # Suffix for the RFDS Review Status Text from each file
    )
    print("3. Merged QuickBase with RFDS Status data using 'P:Viaero Root ID' and 'site #'.")


    # --- 5. Do this IF [RFDS Review Status Text]=[OV RFDS Review Status Text] THEN "OK" ELSE "Update" ENDIF ---
    # The 'RFDS Review Status Text' from QuickBase is named 'RFDS Review Status Text_QB' 
    # The 'RFDS Review Status Text' from Status is named 'RFDS Review Status Text_RFDS_STATUS'
    
    # We need to assume that the 'OV RFDS Review Status Text' column in df_quickbase 
    # is the 'RFDS Review Status Text_QB' from the initial quickbase file.
    
    # Based on the user's mapping (step 10), the input column is 'RFDS Review Status Text', 
    # which is likely the one brought in from the status file (step 3). 
    # Let's assume the comparison is between the **Status File** column and an existing 
    # **QuickBase** column. The prompt is slightly ambiguous on the QuickBase column name.
    # Assuming 'OV RFDS Review Status Text' exists in df_quickbase:
    
    status_qb_col = 'OV RFDS Review Status Text' # Assuming this is the OV column in QuickBase
    status_status_col = 'RFDS Review Status Text_RFDS_STATUS' # Column brought from RFDS Status file

    if status_qb_col in df_quickbase.columns and status_status_col in df_quickbase.columns:
        df_quickbase['Comparison_Result'] = np.where(
            df_quickbase[status_status_col] == df_quickbase[status_qb_col], 
            "OK", 
            "Update"
        )
        print("5. Applied 'OK'/'Update' comparison logic.")
    else:
        print(f"Warning: Columns for comparison ('{status_qb_col}' or '{status_status_col}') not found. Skipping Step 5.")
        df_quickbase['Comparison_Result'] = '' # Add an empty column if logic couldn't run

    # --- 6. VLOOKUP for "CBRS (3.65)Site" from df_rfds_report ---
    # This lookup uses the same key, but with a *different* file (RFDS_report_).
    # Prepare df_rfds_report: Check if necessary columns exist
    required_cols_report = ['Site - Project Name', 'Network Site Name (complete)', 'Site #', 'CBRS (3.65) Site']
    if all(col in df_rfds_report.columns for col in required_cols_report):
        # We need to determine which columns map to 'P:Viaero Root ID' and 'site #' in this file.
        # Based on typical naming conventions, 'Site - Project Name' or 'Network Site Name (complete)' 
        # might be the Root ID, but we'll use the column 'Site #' as per the prompt structure.
        # Assuming P:Viaero Root ID can be found in a site name/ID column. 
        # Since the original files are unavailable, let's assume the merge key structure:
        
        # NOTE: This step assumes 'P:Viaero Root ID' can be extracted or derived from 
        # 'Site - Project Name' or 'Network Site Name (complete)' to match the logic of step 3. 
        # A simpler approach is to assume 'Site #' is the 'site #' column and 
        # a 'Project ID' or similar is the 'P:Viaero Root ID'.
        
        # **Simplified Assumption for Step 6 VLOOKUP Key:** # Assuming 'Site - Project Name' acts as 'P:Viaero Root ID' and 'Site #' is the 'site #'
        df_rfds_report['Join_Key'] = df_rfds_report['Site - Project Name'].astype(str) + df_rfds_report['Site #'].astype(str).str.strip().str.zfill(4)

        cols_to_bring_report = ['Join_Key', 'CBRS (3.65) Site']
        
        df_quickbase = pd.merge(
            df_quickbase,
            df_rfds_report[cols_to_bring_report],
            on='Join_Key',
            how='left'
        )
        print("6. VLOOKUP done to bring 'CBRS (3.65) Site' from RFDS report.")
    else:
        print("Error: Missing required columns in RFDS report file for lookup.")


    # --- 10. Output File Mapping ---
    
    # Define the final columns and their new names
    mapping = {
        'P:Project ID': 'Project ID',
        'CBRS (3.65) Site': 'P_QB_CBRS_365_SITE', # Brought from df_rfds_report (Step 6)
        'P:[QB] Conditional Tower Top': 'P_QB_CONDITIONAL_TOWER_TOP',
        'P:[QB] RFDS Vendor Notes': 'P_QB_RFDS_VENDOR_NOTES',
        'P:[QB] RFDS Approval History': 'P_QB_RFDS_APPROVAL_HISTORY',
        'P:[QB] RFDS Redline Notes': 'P_QB_RFDS_REDLINE_NOTES',
        'P:[QB] RFDS Rejection Notes': 'P_QB_RFDS_REJECTION_NOTES',
        # 'RFDS Review Status Text' maps to 'P_QB_RFDS_REVIEW_STATUS_TEXT'. 
        # We will use the column brought in from the latest status report (Step 3).
        status_status_col: 'P_QB_RFDS_REVIEW_STATUS_TEXT', 
        'Date Added': 'P_QB_DATE_ADDED',
        'Approval Date': 'P_QB_RFDS_DATE_APPROVED',
        'CTO Review Status': 'P_QB_CTO_REVIEW_STATUS',
        'Project Team Review Status': 'P_QB_PROJECT_TEAM_REVIEW_STATUS',
        'RF Engineer Review Status': 'P_QB_RF_ENGINEER_REVIEW_STATUS'
    }

    # Select and rename columns
    final_cols = [col for col in mapping.keys() if col in df_quickbase.columns]
    df_output = df_quickbase[final_cols].rename(columns=mapping)
    
    # Ensure all mapped output columns exist, even if with NaN/empty values
    for new_col in mapping.values():
        if new_col not in df_output.columns:
            df_output[new_col] = None 
            
    # Final cleanup of columns based on the required output names
    df_output = df_output[[
        'Project ID',
        'P_QB_CBRS_365_SITE',
        'P_QB_CONDITIONAL_TOWER_TOP',
        'P_QB_RFDS_VENDOR_NOTES',
        'P_QB_RFDS_APPROVAL_HISTORY',
        'P_QB_RFDS_REDLINE_NOTES',
        'P_QB_RFDS_REJECTION_NOTES',
        'P_QB_RFDS_REVIEW_STATUS_TEXT',
        'P_QB_DATE_ADDED',
        'P_QB_RFDS_DATE_APPROVED',
        'P_QB_CTO_REVIEW_STATUS',
        'P_QB_PROJECT_TEAM_REVIEW_STATUS',
        'P_QB_RF_ENGINEER_REVIEW_STATUS'
    ]]
    print("10. Applied final column mapping.")


    # --- 7. Create a file named QB_RFDS_yyyymmdd ---
    current_date = datetime.now().strftime("%Y%m%d")
    file_name = f"QB_RFDS_{current_date}.csv"
    local_full_path = os.path.join(output_path, file_name)

    # Save locally as CSV
    df_output.to_csv(local_full_path, index=False)
    print(f"7. Output file created locally: {local_full_path}")


    # --- 8. Update this file in the SFTP path ---
    sftp_target_path = "sftp://54.225.75.239:22/home/samsung_sea2/es/Inbound/Rancomm/Quickbase_Reports/RFDS/"
    
    if sftp_upload_function:
        print(f"Attempting to upload to {sftp_target_path}...")
        # NOTE: The sftp_upload_function needs to be provided and handle the logic
        # for connecting to the server and putting the file.
        # Example of how to call it:
        # sftp_upload_function(local_full_path, sftp_target_path)
    else:
        print(f"8. NOTE: SFTP upload logic is not executed as 'sftp_upload_function' was not provided.")
        
    return df_output

# --- Function Call (Example) ---
# NOTE: You would replace these placeholder DataFrames with the ones loaded 
# in your provided code block (e.g., Alteryx.read(1), Alteryx.read(2), etc.)

# # Placeholder DataFrames for testing the logic
# df_quickbase_data = {
#     'P:Viaero Root ID': ['ID1', 'ID2', 'ID3'],
#     'site #': ['1', '20', '300'],
#     'WPK:OV Work Package ID': ['Work1', 'Viaero Trial', 'Work3'],
#     'OV RFDS Review Status Text': ['Approved', 'Rejected', 'Pending'],
#     'P:Project ID': ['P1', 'P2', 'P3'],
#     'P:[QB] Conditional Tower Top': ['Y', 'N', 'Y'],
#     'P:[QB] RFDS Vendor Notes': ['Note1', 'Note2', 'Note3'],
#     'P:[QB] RFDS Approval History': ['Hist1', 'Hist2', 'Hist3'],
#     'P:[QB] RFDS Redline Notes': ['Red1', 'Red2', 'Red3'],
#     'P:[QB] RFDS Rejection Notes': ['Rej1', 'Rej2', 'Rej3'],
#     'Date Added': ['2025-10-01', '2025-10-02', '2025-10-03'],
#     'Approval Date': ['2025-10-05', '2025-10-06', '2025-10-07'],
#     'CTO Review Status': ['C1', 'C2', 'C3'],
#     'Project Team Review Status': ['PT1', 'PT2', 'PT3'],
#     'RF Engineer Review Status': ['RF1', 'RF2', 'RF3'],
# }
# df_quickbase_ex = pd.DataFrame(df_quickbase_data)

# df_rfds_status_data = {
#     'P:Viaero Root ID': ['ID1', 'ID2', 'ID3', 'ID1'],
#     'site #': ['0001', '20', '300', '1'], # Note: site # will be padded in step 2
#     'RFDS Review Status Text': ['Approved', 'Update Status', 'Pending', 'New Approved'],
#     'RFDS': [100, 200, 300, 400] # Duplicates: ID1/1 should be 'New Approved'
# }
# df_rfds_status_ex = pd.DataFrame(df_rfds_status_data)

# df_rfds_report_data = {
#     'Site - Project Name': ['ID1', 'ID2', 'ID3'],
#     'Site #': ['1', '20', '300'],
#     'CBRS (3.65) Site': ['CBRS-A', 'CBRS-B', 'CBRS-C'],
# }
# df_rfds_report_ex = pd.DataFrame(df_rfds_report_data)

# output_directory = r'C:\temp\RFDS_output' 
# os.makedirs(output_directory, exist_ok=True)

# # Run the function
# # final_df = RFDS_Update(df_quickbase_ex, df_rfds_status_ex, df_rfds_report_ex, output_directory)
# # print("\nFinal Processed DataFrame:")
# # print(final_df)
