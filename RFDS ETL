import pandas as pd
import numpy as np
import paramiko
import os
from datetime import datetime
from io import StringIO

# --- 1. SFTP Connection and Upload Function ---
# NOTE: Replace 'XXXX' with your actual credentials for execution.
SFTP_HOST = '54.225.75.239'
SFTP_PORT = 22
SFTP_USERNAME = 'XXXX'
SFTP_PASSWORD = 'XXXX'
SFTP_REMOTE_PATH = '/home/samsung_sea2/es/Inbound/Rancomm/Quickbase_Reports/RFDS/'

def upload_file_to_sftp(local_file_path):
    """Uploads a single file to the specified SFTP server."""
    print(f"\n--- Starting SFTP Upload for: {os.path.basename(local_file_path)} ---")
    
    ssh = None
    sftp = None
    try:
        ssh = paramiko.SSHClient()
        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        
        # Connect to SFTP
        ssh.connect(SFTP_HOST, port=SFTP_PORT, username=SFTP_USERNAME, password=SFTP_PASSWORD)
        sftp = ssh.open_sftp()

        remote_full_path = os.path.join(SFTP_REMOTE_PATH, os.path.basename(local_file_path))
        
        # Ensure the remote directory exists if you have permissions (optional, often skipped)
        # sftp.stat(SFTP_REMOTE_PATH) 

        sftp.put(local_file_path, remote_full_path)
        print(f"✅ File uploaded successfully to: {remote_full_path}")
        return True

    except Exception as e:
        print(f"❌ An error occurred during SFTP upload. Check credentials and permissions: {e}")
        return False
    finally:
        if sftp:
            sftp.close()
        if ssh:
            ssh.close()

# --- 2. Main Data Processing Function (RFDS_Update) ---

def RFDS_Update(df_quickbase, df_rfds_status, df_rfds_report, output_path='./output_files'):
    """
    Performs data manipulation, lookups, filtering, and saves/uploads the final RFDS Update file.
    """
    
    print("\n--- Starting RFDS Update Data Processing ---")
    
    # --- 1. Filter df_quickbase ---
    column_to_filter = 'WPK:OV Work Package ID'
    if column_to_filter in df_quickbase.columns:
        df_quickbase = df_quickbase[~df_quickbase[column_to_filter].astype(str).str.contains('Viaero Trial', na=False, case=False)].copy()
        print("Step 1: Filtered QuickBase to exclude 'Viaero Trial'.")

    # --- 2. Complete "site #" in df_rfds_status with "0" until 4 digits ---
    site_col = 'site #'
    if site_col in df_rfds_status.columns:
        df_rfds_status[site_col] = df_rfds_status[site_col].astype(str).str.strip().str.zfill(4)
        print("Step 2: Padded 'site #' in RFDS status file.")
    
    # --- Prepare for Merges (Create Join Key) ---
    df_quickbase['Join_Key'] = df_quickbase['P:Viaero Root ID'].astype(str) + df_quickbase['site #'].astype(str)
    df_rfds_status['Join_Key'] = df_rfds_status['P:Viaero Root ID'].astype(str) + df_rfds_status[site_col].astype(str)
    
    # --- 4. Handle Duplicates in df_rfds_status ---
    # Sort by 'Join_Key' and 'RFDS', keep the LAST (latest) occurrence
    df_rfds_status = df_rfds_status.sort_values(by=['Join_Key', 'RFDS'], ascending=[True, True]).drop_duplicates(subset=['Join_Key'], keep='last').copy()
    print("Step 4: Handled duplicates in RFDS status file (kept latest by RFDS column).")
    
    # --- 3. VLOOKUP (Merge df_quickbase with df_rfds_status) ---
    status_cols_to_bring = [
        'RFDS Review Status Text', 
        'Date Added', 
        'Approval Date', 
        'CTO Review Status', 
        'Project Team Review Status', 
        'RF Engineer Review Status'
    ]
    
    # Rename status columns for merging
    status_rename_map = {col: f"{col}_RFDS_STATUS" for col in status_cols_to_bring}
    df_status_for_merge = df_rfds_status[['Join_Key'] + status_cols_to_bring].rename(columns=status_rename_map)

    df_quickbase = pd.merge(df_quickbase, df_status_for_merge, on='Join_Key', how='left')
    print("Step 3: Merged QuickBase with RFDS Status data.")

    # --- 5. Conditional Logic: IF/THEN/ELSE ---
    status_qb_col = 'OV RFDS Review Status Text' 
    status_status_col = 'RFDS Review Status Text_RFDS_STATUS' 
    
    if status_qb_col in df_quickbase.columns and status_status_col in df_quickbase.columns:
        df_quickbase['Comparison_Result'] = np.where(
            df_quickbase[status_status_col] == df_quickbase[status_qb_col], 
            "OK", 
            "Update"
        )
        print("Step 5: Applied 'OK'/'Update' comparison logic.")
    else:
        df_quickbase['Comparison_Result'] = "OK" 
        print(f"Warning: Missing column for comparison ('{status_qb_col}' or '{status_status_col}'). Defaulting to 'OK'.")
        
    
    # --- 6. VLOOKUP for "CBRS (3.65)Site" from df_rfds_report ---
    if not df_rfds_report.empty and 'Site - Project Name' in df_rfds_report.columns and 'Site #' in df_rfds_report.columns:
        # Create join key for RFDS report: assuming 'Site - Project Name' is the root ID
        df_rfds_report['Join_Key'] = df_rfds_report['Site - Project Name'].astype(str) + df_rfds_report['Site #'].astype(str).str.strip().str.zfill(4)
        
        df_quickbase = pd.merge(
            df_quickbase,
            df_rfds_report[['Join_Key', 'CBRS (3.65) Site']],
            on='Join_Key',
            how='left'
        )
        print("Step 6: VLOOKUP done to bring 'CBRS (3.65) Site'.")
    else:
        df_quickbase['CBRS (3.65) Site'] = np.nan
        print("Warning: RFDS report file is empty/missing key columns. Skipping CBRS lookup.")


    # --- 1. Final Filter: Only rows that have the filter "update" ---
    df_output_filtered = df_quickbase[df_quickbase['Comparison_Result'] == 'Update'].copy()
    print(f"\nFinal Filter applied. Kept {len(df_output_filtered)} rows with 'Update' status.")

    if df_output_filtered.empty:
        print("⚠️ No rows meet the 'Update' criteria. Skipping file creation and upload.")
        return pd.DataFrame()
        
    # --- 10. Output File Mapping ---
    mapping = {
        'P:Project ID': 'Project ID',
        'CBRS (3.65) Site': 'P_QB_CBRS_365_SITE',
        'P:[QB] Conditional Tower Top': 'P_QB_CONDITIONAL_TOWER_TOP',
        'P:[QB] RFDS Vendor Notes': 'P_QB_RFDS_VENDOR_NOTES',
        'P:[QB] RFDS Approval History': 'P_QB_RFDS_APPROVAL_HISTORY',
        'P:[QB] RFDS Redline Notes': 'P_QB_RFDS_REDLINE_NOTES',
        'P:[QB] RFDS Rejection Notes': 'P_QB_RFDS_REJECTION_NOTES',
        'RFDS Review Status Text_RFDS_STATUS': 'P_QB_RFDS_REVIEW_STATUS_TEXT', 
        'Date Added_RFDS_STATUS': 'P_QB_DATE_ADDED',
        'Approval Date_RFDS_STATUS': 'P_QB_RFDS_DATE_APPROVED',
        'CTO Review Status_RFDS_STATUS': 'P_QB_CTO_REVIEW_STATUS',
        'Project Team Review Status_RFDS_STATUS': 'P_QB_PROJECT_TEAM_REVIEW_STATUS',
        'RF Engineer Review Status_RFDS_STATUS': 'P_QB_RF_ENGINEER_REVIEW_STATUS'
    }

    # Select and rename columns
    final_output_cols = [col for col in mapping.keys() if col in df_output_filtered.columns]
    df_output = df_output_filtered[final_output_cols].rename(columns=mapping)
    print("Step 10: Applied final column mapping.")

    
    # --- 7. Create local file named QB_RFDS_yyyymmdd ---
    os.makedirs(output_path, exist_ok=True)
    current_date = datetime.now().strftime("%Y%m%d")
    file_name = f"QB_RFDS_{current_date}.csv"
    local_full_path = os.path.join(output_path, file_name)

    # Save locally as CSV
    df_output.to_csv(local_full_path, index=False)
    print(f"\nStep 7: Output file created locally: {local_full_path}")


    # --- 8. Update this file in the SFTP path (using provided format) ---
    upload_file_to_sftp(local_full_path)
        
    return df_output

# --- 3. Example Data Setup (Use your download logic to populate these) ---

# NOTE: In your real environment, you would use the download functions 
# you provided earlier to load these DataFrames instead of these dummy ones.

data_quickbase = {
    'P:Viaero Root ID': ['ID1', 'ID2', 'ID3', 'ID4'],
    'site #': ['1', '20', '300', '4000'],
    'WPK:OV Work Package ID': ['Work1', 'Viaero Trial', 'Work3', 'Work4'],
    'OV RFDS Review Status Text': ['Approved', 'Rejected', 'Pending', 'Pending'],
    'P:Project ID': ['P1', 'P2', 'P3', 'P4'],
    'P:[QB] Conditional Tower Top': ['Y', 'N', 'Y', 'Y'],
    'P:[QB] RFDS Vendor Notes': ['Note1', 'Note2', 'Note3', 'Note4'],
    'P:[QB] RFDS Approval History': ['Hist1', 'Hist2', 'Hist3', 'Hist4'],
    'P:[QB] RFDS Redline Notes': ['Red1', 'Red2', 'Red3', 'Red4'],
    'P:[QB] RFDS Rejection Notes': ['Rej1', 'Rej2', 'Rej3', 'Rej4'],
}
df_quickbase_ex = pd.DataFrame(data_quickbase)

data_rfds_status = {
    'P:Viaero Root ID': ['ID1', 'ID2', 'ID3', 'ID1'],
    'site #': ['1', '20', '300', '1'], 
    'RFDS Review Status Text': ['Approved', 'Update Status', 'New Status', 'New Approved'],
    'RFDS': [100, 200, 300, 400], # Latest RFDS value is 400 for ID1/1
    'Date Added': ['2025-10-01', '2025-10-02', '2025-10-03', '2025-10-10'],
    'Approval Date': ['2025-10-05', '2025-10-06', '2025-10-07', '2025-10-11'],
    'CTO Review Status': ['C1', 'C2', 'C3', 'C4'],
    'Project Team Review Status': ['PT1', 'PT2', 'PT3', 'PT4'],
    'RF Engineer Review Status': ['RF1', 'RF2', 'RF3', 'RF4'],
}
df_rfds_status_ex = pd.DataFrame(data_rfds_status)

data_rfds_report = {
    'Site - Project Name': ['ID1', 'ID2', 'ID3', 'ID4'],
    'Site #': ['1', '20', '300', '4000'],
    'CBRS (3.65) Site': ['CBRS-A', 'CBRS-B', 'CBRS-C', 'CBRS-D'],
}
df_rfds_report_ex = pd.DataFrame(data_rfds_report)

# --- 4. Execution ---

# ⚠️ WARNING: Update the SFTP credentials at the top of the script before running!
final_output_df = RFDS_Update(df_quickbase_ex, df_rfds_status_ex, df_rfds_report_ex)

print("\n--- Final Output DataFrame (Only 'Update' Rows) ---")
print(final_output_df)

