import paramiko
import pandas as pd
import os
from datetime import datetime
import openpyxl
import re 

# --- SFTP Functions (Remain the same, but used twice) ---

def get_latest_file(sftp, remote_file_path, file_prefix):
    """
    Get the latest file from the SFTP server based on the file prefix.
    """
    files = sftp.listdir(remote_file_path)
    latest_file = None
    latest_timestamp = None
    for file in files:
        if file.startswith(file_prefix):
            try:
                file_stat = sftp.stat(os.path.join(remote_file_path, file))
                timestamp_obj = datetime.fromtimestamp(file_stat.st_mtime)
                
                if latest_timestamp is None or timestamp_obj > latest_timestamp:
                    latest_timestamp = timestamp_obj
                    latest_file = file
            except (ValueError, IndexError):
                continue
    return latest_file

def download_file_from_sftp_to_network(output_network_path, host, port, username, password, remote_file_path, file_prefix):
    """
    Downloads a single file from an SFTP server to a specified network directory.
    Returns the full local path of the downloaded file.
    """
    print(f"Starting SFTP file download for prefix: {file_prefix}")
    ssh = None
    sftp = None
    try:
        os.makedirs(output_network_path, exist_ok=True)

        ssh = paramiko.SSHClient()
        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        ssh.connect(host, port=port, username=username, password=password)
        sftp = ssh.open_sftp()

        latest_file = get_latest_file(sftp, remote_file_path, file_prefix)
        if latest_file:
            full_remote_path = os.path.join(remote_file_path, latest_file)
            full_local_path = os.path.join(output_network_path, latest_file)
            print(f"Downloading file: {full_remote_path} to {full_local_path}")
            try:
                sftp.get(full_remote_path, full_local_path)
                print(f"File downloaded successfully to {full_local_path}")
                return full_local_path
            except Exception as e:
                print(f"Error downloading file: {e}")
        else:
            print(f"No matching files found with prefix {file_prefix} in the specified SFTP directory.")
            return None

    except Exception as e:
        print(f"An error occurred during SFTP download: {e}")
        return None
    finally:
        if sftp:
            sftp.close()
        if ssh:
            ssh.close()

# --- Core Processing Function (Same logic, but now expecting two downloaded paths) ---

def process_and_compare_files(quote_report_path, quote_tracker_path):
    """
    Reads the two files, extracts Quote ID from the report, and compares them 
    on the 'QT:Quote ID' key to find discrepancies.
    """
    print(f"\n--- Starting comparison between: {os.path.basename(quote_report_path)} and {os.path.basename(quote_tracker_path)} ---")
    
    try:
        # Read the Quote Report (CSV)
        df_quotes = pd.read_csv(quote_report_path)
        # Read the Quote Tracker (Excel)
        df_tracker = pd.read_excel(quote_tracker_path, engine='openpyxl')
    except FileNotFoundError as e:
        print(f"Error: One of the downloaded files was not found at its local path. Details: {e}")
        return
    except Exception as e:
        print(f"Error reading files: {e}")
        return

    # Clean column names
    df_quotes.columns = df_quotes.columns.str.strip()
    df_tracker.columns = df_tracker.columns.str.strip()

    # --- NEW: Extract QT:Quote ID from 'Document' column (Quotes_Report_) ---
    if 'Document' in df_quotes.columns:
        try:
            # We are extracting the unique Quote ID from the Document column
            split_df = df_quotes['Document'].astype(str).str.split('_', n=1, expand=True)
            df_quotes['QT:Quote ID'] = split_df[1].str.strip()
            
            # Since 'Site #' is no longer the merge key, we keep this for context
            if 'Site #' in df_quotes.columns:
                df_quotes['Site #'] = df_quotes['Site #'].astype(str).str.strip().str.upper().str.zfill(4)
        except KeyError:
            print("Warning: Could not extract 'QT:Quote ID' from 'Document' column.")
            df_quotes['QT:Quote ID'] = None
            return
    else:
        print("Error: The required 'Document' column was not found in the report.")
        return

    # --- Data Standardization for Merge ---
    # 1. Rename the Tracker's Site ID to match the Report's naming convention for comparison later
    if 'QT:Root Cell ID' in df_tracker.columns:
        df_tracker.rename(columns={'QT:Root Cell ID': 'Site #'}, inplace=True)
        # Standardize Site # in the local tracker
        df_tracker['Site #'] = df_tracker['Site #'].astype(str).str.strip().str.upper().str.zfill(4)
    else:
        print("Error: The required 'QT:Root Cell ID' was not found in the Tracker file.")
        return
    
    # 2. Ensure the Quote IDs are clean strings in both files for a reliable match
    if 'QT:Quote ID' in df_tracker.columns:
        df_tracker['QT:Quote ID'] = df_tracker['QT:Quote ID'].astype(str).str.strip()
    else:
        print("Error: The required 'QT:Quote ID' column was not found in the Tracker file.")
        return

    # --- CRITICAL CHANGE: Merge on the unique "QT:Quote ID" key ---
    merged_df = pd.merge(
        df_quotes,
        df_tracker,
        on='QT:Quote ID', # <--- MERGING ON THE UNIQUE ID
        how='left',
        suffixes=('_quotes', '_tracker')
    )

    # --- Comparison Logic ---
    # Requirement 3: Concatenate key columns from Quotes_Report_
    merged_df['Conca_quotes'] = merged_df[[
        'Site #_quotes', 'Document Type - RAN', 'Review History',
        'Doc Review Status Text', 'Rejection Notes', 'Date Approved'
    ]].astype(str).agg('|'.join, axis=1)

    # Requirement 4: Concatenate key columns from Quote_Tracker_Data_
    merged_df['Conca_tracker'] = merged_df[[
        'Site #_tracker', 'QT:QB - Document Type', 'QT:QB - Review History',
        'QT:QB - Doc Review Status Text', 'QT:QB - Rejection Notes', 'QT:QB - Date Approved'
    ]].astype(str).agg('|'.join, axis=1)

    # Requirement 5: Compare and find differences
    df_diff = merged_df[merged_df['Conca_quotes'] != merged_df['Conca_tracker']]

    
    # ====================================================================
    # === OUTPUT: DEBUG/COMPARISON FILE (The one you asked for) ===
    # ====================================================================
    if not df_diff.empty:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        debug_file_name = f"DEBUG_Comparison_Differences_Raw_{timestamp}.xlsx"
        debug_output_path = os.path.join(os.path.dirname(quote_report_path), debug_file_name)
        
        # Save ALL columns from the merged (differing) rows to the debug file
        df_diff.to_excel(debug_output_path, index=False)
        print(f"\n*** COMPARISON DEBUG FILE CREATED ***: Differences (merged raw data) saved to: {debug_output_path}")

    # ====================================================================
    # === OUTPUT: FINAL PROCESSED REPORT (Requirement 6) ===
    # ====================================================================
    if not df_diff.empty:
        df_output = df_diff[[
            'QT:Quote ID',
            'Submittal Date',
            'Document Type - RAN',
            'Review History',
            'Doc Review Status Text',
            'Date Approved',
            'Rejection Notes',
            'Redline Notes'
        ]].rename(columns={
            'QT:Quote ID': 'QUOTE_TRACKER_XITOR_KEY',
            'Submittal Date': 'QT_SUBMITTAL_DATE',
            'Document Type - RAN': 'QT_QB__DOCUMENT_TYPE',
            'Review History': 'QT_QB__REVIEW_HISTORY',
            'Doc Review Status Text': 'QT_QB__DOC_REVIEW_STATUS_TEXT',
            'Date Approved': 'QT_QB__DATE_APPROVED',
            'Rejection Notes': 'QT_QB__REJECTION_NOTES',
            'Redline Notes': 'QT_QB_RED_LINE_NOTES'
        })
        
        # Save the differences to a new Excel file with a timestamp
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file_name = f"QB_Quotes_Discrepancy_Report_{timestamp}.xlsx"
        output_path = os.path.join(os.path.dirname(quote_report_path), output_file_name)
        df_output.to_excel(output_path, index=False)
        print(f"Final Discrepancy Report saved to: {output_path}")
    else:
        print("No differences found between the two files. Final report not created.")

# Main script execution
if __name__ == '__main__':
    # --- SFTP Configuration ---
    SFTP_HOST = 'your_sftp_host'
    SFTP_PORT = 22 
    SFTP_USERNAME = 'your_username'
    SFTP_PASSWORD = 'your_password'
    REMOTE_DIR = '/path/on/sftp/server/' # Assuming both files are in the same remote directory
    LOCAL_NETWORK_PATH = 'C:\\Local\\Output\\Path\\'

    # --- FILE PREFIXES ---
    FILE_PREFIX_REPORT = 'Quotes_Report_' 
    # !!! IMPORTANT: Replace 'Quote_Tracker_Data_' with the ACTUAL prefix of the Tracker file on SFTP
    FILE_PREFIX_TRACKER = 'Quote_Tracker_Data_' 

    # 1. Download the latest Quotes_Report_.csv file
    downloaded_report_path = download_file_from_sftp_to_network(
        LOCAL_NETWORK_PATH, 
        SFTP_HOST, 
        SFTP_PORT, 
        SFTP_USERNAME, 
        SFTP_PASSWORD, 
        REMOTE_DIR, 
        FILE_PREFIX_REPORT
    )

    # 2. Download the latest Quote_Tracker_Data_.xlsx file
    downloaded_tracker_path = download_file_from_sftp_to_network(
        LOCAL_NETWORK_PATH, 
        SFTP_HOST, 
        SFTP_PORT, 
        SFTP_USERNAME, 
        SFTP_PASSWORD, 
        REMOTE_DIR, 
        FILE_PREFIX_TRACKER
    )

    # 3. Process and compare both downloaded files
    if downloaded_report_path and downloaded_tracker_path:
        process_and_compare_files(downloaded_report_path, downloaded_tracker_path)
    else:
        print("\nCould not proceed with file processing as one or both files were not downloaded.")
