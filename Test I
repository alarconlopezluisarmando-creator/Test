# Import libraries
import pandas as pd
from datetime import datetime
from ayx import Alteryx
import re
import warnings

# Suppress the UserWarning from pandas about openpyxl
warnings.simplefilter(action='ignore', category=UserWarning)

# --- Step 2: Define file path and read data ---
file_path = r"\\netapp\depts\Jannat\Viaero\BMS_TrackerProgress.xlsx"
df = None

try:
    df = pd.read_excel(file_path, engine='openpyxl')
    print("File read successfully.")
except FileNotFoundError:
    print(f"Error: File not found at {file_path}")
    df = pd.DataFrame({'Error': ["File not found."]})
except Exception as e:
    print(f"Error reading file: {e}")
    df = pd.DataFrame({'Error': [f"File reading failed: {e}"]})

if 'Error' in df.columns:
    Alteryx.write(df, 1)
    exit()

# --- Step 3: Unpivot the milestone data ---
id_vars = [
    'CL:Customer Name', 'P:Viaero Root ID', 'C:Site Name (SPMS)',
    'WPK:Work Package Description', 'P:Project ID', 'C:Site ID',
    'P:Viaero Phase', 'P:Viaero Project Type', 'P:Cluster ID',
    'P:FWA (Existing)', 'P:FWA (Scope)', 'P:FWA (Final)',
    'P:Mobility (Existing)', 'P:Mobility (Scope)', 'P:Mobility (Final)',
    'M:Market', 'P:Project Class', 'P:Project Status'
]

milestone_cols = [col for col in df.columns if col.startswith('V:(')]
df_unpivoted = df.melt(id_vars=id_vars, value_vars=milestone_cols, var_name='Milestone', value_name='Status')

# --- Step 4: Extract required columns from unpivoted data ---
def extract_f_a(milestone_str):
    match = re.search(r'V:\((F|A)', milestone_str)
    return 'Forecast' if match and match.group(1) == 'F' else 'Actual'

milestone_mapping = {
    'Site Audit Walk Package Received-Finish': ('Site Audit Walk Package Received-Finish', 'Pre-Con - Site Walk'),
    'Ground Cabling BOM Received-Finish': ('Ground Cabling BOM Received-Finish\n Tower Cabling BOM Received-Finish', 'Pre-Con - Cable BOM and LE'),
    'Tower Cabling BOM Received-Finish': ('Ground Cabling BOM Received-Finish\n Tower Cabling BOM Received-Finish', 'Pre-Con - Cable BOM and LE - Tower'),
    '100% Construction Drawing Received-Finish': ('100% Construction Drawing Received-Finish', 'Pre-Con - Final Drawings'),
    'Billing Milestone 1 Complete-Finish': ('Billing Milestone 1 Complete', 'Pre-Con - Ms1 Rev Rec'),
    'Viaero Ground NTP Received-Finish': ('Viaero Ground NTP Received-Finish', 'Ground NTP'),
    'Ground Construction Complete-Finish': ('Ground Construction Complete-Finish', 'BBU - Ground Install (sites)'),
    'Billing Milestone 2 Complete-Finish': ('Billing Milestone 2 Complete', 'BBU - MS2 Rev Rec'),
    'Viaero Tower NTP Received-Finish': ('Viaero Tower NTP Received-Finish', 'Tower NTP'),
    'Tower Construction Start-Finish': ('Tower Construction Start', 'RRH - Tower CxS'),
    'Tower Installation Complete-Finish': ('Tower Installation Complete', 'RRH - Tower CxC'),
    'Billing Milestone 3 Complete-Finish': ('Billing Milestone 3 Complete', 'MS3 Rev Rec'),
    'Billing Milestone 4 Complete-Finish': ('Billing Milestone 4 Complete', 'MS4 Rev Rec'),
    'De-installed Equipment Return Completed-Finish': ('De-installed Equipment Return Completed', 'Cx Decom'),
    'Site Acceptance-Finish': ('Site Acceptance', 'MS5 - Final Site Acceptance'),
    'Billing Milestone 5 Complete-Finish': ('Billing Milestone 5 Complete', 'MS5 - Final Site Acceptance Rev Rec')
}

def extract_names(milestone_str):
    match = re.search(r'V:\((F|A)\s\d{4}\)\s(.*)', milestone_str)
    milestone_name = match.group(2) if match else milestone_str
    return milestone_mapping.get(milestone_name, (milestone_name, milestone_name))

df_unpivoted['F/A'] = df_unpivoted['Milestone'].apply(extract_f_a)
df_unpivoted[['Task Name', 'New name']] = df_unpivoted['Milestone'].apply(lambda x: pd.Series(extract_names(x)))
df_unpivoted['Weekly'] = df_unpivoted['New name']

# --- Step 5: Prepare data for weekly and monthly reports ---
# Convert 'Status' column to datetime, forcing invalid dates to NaT
df_unpivoted['Status'] = pd.to_datetime(df_unpivoted['Status'], errors='coerce')

# Filter for rows with valid dates for the report
df_with_dates = df_unpivoted.dropna(subset=['Status']).copy()

# Add a 'Milestone_Count' column for aggregation
df_with_dates['Milestone_Count'] = 1

# Create 'Week of Year' and 'Month_Year' columns for pivoting
df_with_dates['Week of Year'] = df_with_dates['Status'].dt.isocalendar().week.astype(str) + '-' + df_with_dates['Status'].dt.year.astype(str)
df_with_dates['Month_Year'] = df_with_dates['Status'].dt.to_period('M')

# --- Step 6: Create weekly and monthly reports using pivot tables ---
# Weekly Report
weekly_pivot = pd.pivot_table(
    df_with_dates,
    values='Milestone_Count',
    index=['Weekly', 'F/A', 'Task Name'],
    columns=['Week of Year'],
    aggfunc='sum',
    fill_value=0
)
final_weekly_report = weekly_pivot

# Monthly Report
monthly_pivot = pd.pivot_table(
    df_with_dates,
    values='Milestone_Count',
    index=['Weekly', 'F/A', 'Task Name'],
    columns=['Month_Year'],
    aggfunc='sum',
    fill_value=0
)
final_monthly_report = monthly_pivot

# --- Step 7: Write reports to multi-sheet Excel file ---
today = datetime.today()
output_filename = r"Viaero_BMS_ProgressTracker_" + today.strftime("%m.%d.%y") + "_OV MS rev1.xlsx"
try:
    with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:
        final_weekly_report.to_excel(writer, sheet_name='Weekly Report')
        final_monthly_report.to_excel(writer, sheet_name='Monthly Report')
    print(f"Report saved successfully to {output_filename}")
except Exception as e:
    print(f"Error writing to Excel file: {e}")

# --- Step 8: Pass a DataFrame back to Alteryx ---
# Flatten the weekly report for Alteryx
final_weekly_report_flat = final_weekly_report.reset_index()
# Rename columns to a flat list for Alteryx
final_weekly_report_flat.columns = ['Weekly', 'F/A', 'Task Name'] + [col for col in final_weekly_report.columns]

Alteryx.write(final_weekly_report_flat, 1)

This YouTube video explains how to use the `pd.melt()` function to unpivot dataframes in Python, a process similar to the one in your code. 
[Unpivoting dataframes with Pandas melt](https://www.youtube.com/watch?v=ZvqONDEF1sw)
http://googleusercontent.com/youtube_content/0 *YouTube video views will be stored in your YouTube History, and your data will be stored and used by YouTube according to its [Terms of Service](https://www.youtube.com/static?template=terms)*


