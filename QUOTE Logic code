import paramiko
import pandas as pd
import os
from datetime import datetime
import openpyxl

def get_latest_file(sftp, remote_file_path, file_prefix):
    """Get the latest file from the SFTP server based on the file prefix."""
    files = sftp.listdir(remote_file_path)
    latest_file = None
    latest_timestamp = None
    for file in files:
        if file.startswith(file_prefix):
            try:
                # If no timestamp format is provided, use the file's last modified time
                file_stat = sftp.stat(os.path.join(remote_file_path, file))
                timestamp_obj = datetime.fromtimestamp(file_stat.st_mtime)
                
                if latest_timestamp is None or timestamp_obj > latest_timestamp:
                    latest_timestamp = timestamp_obj
                    latest_file = file
            except (ValueError, IndexError):
                continue
    return latest_file

def download_file_from_sftp_to_network(output_network_path, host, port, username, password, remote_file_path, file_prefix):
    """Downloads a single file from an SFTP server to a specified network directory."""
    print("Starting SFTP file download...")
    ssh = None
    sftp = None
    try:
        os.makedirs(output_network_path, exist_ok=True)

        ssh = paramiko.SSHClient()
        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        ssh.connect(host, port=port, username=username, password=password)
        sftp = ssh.open_sftp()

        latest_file = get_latest_file(sftp, remote_file_path, file_prefix)
        if latest_file:
            full_remote_path = os.path.join(remote_file_path, latest_file)
            full_local_path = os.path.join(output_network_path, latest_file)
            print(f"Downloading file: {full_remote_path} to {full_local_path}")
            try:
                sftp.get(full_remote_path, full_local_path)
                print(f"File downloaded successfully to {full_local_path}")
                return full_local_path
            except Exception as e:
                print(f"Error downloading file: {e}")
        else:
            print("No matching files found in the specified SFTP directory.")
            return None

    except Exception as e:
        print(f"An error occurred during SFTP download: {e}")
        return None
    finally:
        if sftp:
            sftp.close()
        if ssh:
            ssh.close()

def process_and_compare_files(quote_summary_path, quote_tracker_path):
    """
    Processes and compares the two files based on the specified requirements.
    """
    # Define the column name maps for each file
    quotes_summary_map = {
        'Site #': 'Site #',
        'Submittal Date': 'Submittal Date',
        'Document Type - RAN': 'Document Type - RAN',
        'Review History': 'Review History',
        'Doc Review Status Text': 'Doc Review Status Text',
        'Date Approved': 'Date Approved',
        'Rejection Notes': 'Rejection Notes',
        'Redline Notes': 'Redline Notes'
    }

    tracker_data_map = {
        'Site #': 'Site #',
        'QT:Quote ID': 'QT:Quote ID',
        'QT:QB - Document Type': 'QT:QB - Document Type',
        'QT:QB - Doc Review Status Text': 'QT:QB - Doc Review Status Text',
        'QT:QB - Date Approved': 'QT:QB - Date Approved',
        'QT:QB - Rejection Notes': 'QT:QB - Rejection Notes',
        'QT:QB - Review History': 'QT:QB - Review History'
    }

    try:
        df_quotes = pd.read_csv(quote_summary_path)
        df_tracker = pd.read_excel(quote_tracker_path, engine='openpyxl')
    except FileNotFoundError:
        print("Error: One of the files was not found.")
        return
    except Exception as e:
        print(f"Error reading files: {e}")
        return
    
    print("Quotes Summary Columns:", df_quotes.columns)
    print("Quote Tracker Columns:", df_tracker.columns)
    
    # Clean column names to remove any leading/trailing spaces
    df_quotes.columns = df_quotes.columns.str.strip()
    df_tracker.columns = df_tracker.columns.str.strip()
    
    print("Quotes Summary Columns after stripping:", df_quotes.columns)
    print("Quote Tracker Columns after stripping:", df_tracker.columns)
    
    # Check if 'Site #' column exists
    if 'Site #' in df_quotes.columns:
        print("'Site #' column exists in df_quotes")
    else:
        print("'Site #' column does not exist in df_quotes")
        
    # Try accessing the 'Site #' column directly
    try:
        print(df_quotes['Site #'].head())
    except Exception as e:
        print(f"Error accessing 'Site #' column: {e}")

    # Rename columns using the defined maps
    try:
        df_quotes.rename(columns=quotes_summary_map, inplace=True)
        df_tracker.rename(columns=tracker_data_map, inplace=True)
    except KeyError as e:
        print(f"Error: The required column {e} was not found in one of the files.")
        print("Please check your file headers for typos, extra spaces, or inconsistent naming.")
        return
        
    # Requirement 1: Format "Site #" in Quotes_Summary_
    df_quotes['Site #'] = df_quotes['Site #'].astype(str).str.zfill(4)

    # Merge the two dataframes on the common "Site #" key
    merged_df = pd.merge(
        df_quotes, 
        df_tracker,
        on='Site #', 
        how='outer',
        suffixes=('_quotes', '_tracker')
    )

    # Requirement 3: Concatenate columns from Quotes_Summary_
    merged_df['Conca_quotes'] = merged_df[[
        'Site #', 'Document Type - RAN', 'Review History', 
        'Doc Review Status Text', 'Rejection Notes', 'Date Approved'
    ]].astype(str).agg('|'.join, axis=1)

    # Requirement 4: Concatenate columns from Quote_Tracker_Data_
    merged_df['Conca_tracker'] = merged_df[[
        'QT:Quote ID', 'QT:QB - Document Type', 'QT:QB - Review History',
        'QT:QB - Doc Review Status Text', 'QT:QB - Rejection Notes',
        'QT:QB - Date Approved'
    ]].astype(str).agg('|'.join, axis=1)

    # Requirement 5: Compare and find differences
    # Identify rows where the concatenated strings are different
    df_diff = merged_df[merged_df['Conca_quotes'] != merged_df['Conca_tracker']]

    # Requirement 6: Reorder and rename columns for the new file
    if not df_diff.empty:
        df_output = df_diff[[
            'QT:Quote ID_tracker',
            'QT:QB - Document Type',
            'Submittal Date',
            'QT:QB - Doc Review Status Text',
            'QT:QB - Rejection Notes',
            'QT:QB - Date Approved',
            'Redline Notes',
            'QT:QB - Review History'
        ]].rename(columns={
            'QT:Quote ID_tracker': 'QUOTE_TRACKER_XITOR_KEY',
            'QT:QB - Document Type': 'QT_QB__DOCUMENT_TYPE',
            'Submittal Date': 'QT_SUBMITTAL_DATE',
            'QT:QB - Doc Review Status Text': 'QT_QB__DOC_REVIEW_STATUS_TEXT',
            'QT:QB - Rejection Notes': 'QT_QB__REJECTION_NOTES',
            'QT:QB - Date Approved': 'QT_QB__DATE_APPROVED',
            'Redline Notes': 'QT_QB_RED_LINE_NOTES',
            'QT:QB - Review History': 'QT_QB__REVIEW_HISTORY'
        })
        
        # Save the differences to a new Excel file with a timestamp
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file_name = f"QB_Quotes_timestamp_{timestamp}.xlsx"
        output_path = os.path.join(os.path.dirname(quote_summary_path), output_file_name)
        df_output.to_excel(output_path, index=False)
        print(f"Differences saved to: {output_path}")
    else:
        print("No differences found between the two files.")
==Error site

'Site #' column exists in df_quotes
0    264.0
1    581.0
2    342.0
3    276.0
4    394.0
Name: Site #, dtype: float64
An error occurred during file processing: 'Site #'
